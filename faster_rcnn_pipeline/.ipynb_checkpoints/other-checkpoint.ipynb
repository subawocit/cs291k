{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb84a95-664f-41c2-a2a5-346512e44870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# import timm\n",
    "\n",
    "# assert timm.__version__ == \"0.3.2\"  # version check\n",
    "# import timm.optim.optim_factory as optim_factory\n",
    "\n",
    "# import util.misc as misc\n",
    "# from util.datasets import build_fmow_dataset\n",
    "# from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "\n",
    "# import models_mae\n",
    "# import models_mae_group_channels\n",
    "# import models_mae_temporal\n",
    "\n",
    "# from engine_pretrain import train_one_epoch, train_one_epoch_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b93c2f-80ce-4660-a145-5c7686c9fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "path = '/hdd/yuchen/satdata/landslides/train_numpy_images/'\n",
    "filename = 'LT05_L1TP_129038_19860731_20170221_01_T1_patch_1280_0.npy'\n",
    "\n",
    "img = np.load(path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31581060-8566-495a-a68e-fd5c28f1d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = '/hdd/yuchen/satdata/landslides/train_yolo_labels/' + filename.split('/')[-1].split('.')[0] + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44b7ef4d-7205-4b71-b885-99fded063fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/hdd/yuchen/satdata/landslides/train_yolo_labels/LT05_L1TP_129038_19860731_20170221_01_T1_patch_1280_0.txt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b341fb0c-197f-4b78-baa9-8602e7d80c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(label, 'r') as file:\n",
    "    file_content = file.read()\n",
    "    file_content = file_content.split('\\n')\n",
    "\n",
    "lst = [item.split(' ') for item in file_content]\n",
    "\n",
    "coords = []\n",
    "for i in lst:\n",
    "    coords_temp = []\n",
    "    for j in i[1:]:\n",
    "        coords_temp.append(float(j))\n",
    "    coords.append(np.array(coords_temp, dtype='object').reshape(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55872fd2-ca31-470a-8b03-f50a774ed73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "841f5172-9902-44bc-adfa-f59c1d2cc46b",
   "metadata": {},
   "source": [
    "[3,4,0]\n",
    "[2,3,0]\n",
    "[2, 0, 4]\n",
    "[0,2,6]\n",
    "[4,0,6]\n",
    "[5,3,6]\n",
    "[3,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "241bd0f5-c214-42e2-8772-38627a0009fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct = 0\n",
    "# # for filename in glob.glob(path+'*'):\n",
    "# for filename in [filename]:\n",
    "#     img = np.load(path+filename)\n",
    "#     for i in range(20):\n",
    "#         fig, axs = plt.subplots(1, 2, figsize=(20,20))\n",
    "#         # plt.figure(figsize=(12,12))\n",
    "#         for idx in range(len(coords[:-1])):\n",
    "#             x, y = coords[idx][:,0]*img.shape[1], coords[idx][:,1]*img.shape[2]\n",
    "#             axs[0].plot(x, y) \n",
    "#         # plt.imshow(img[i])\n",
    "#         selected_channels = np.random.choice(7, 3, replace=False)\n",
    "#         axs[0].imshow(np.moveaxis(img[selected_channels], 0, 2))\n",
    "#         axs[1].imshow(np.moveaxis(img[selected_channels], 0, 2))\n",
    "#         axs[0].set_title(filename + str(selected_channels))\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c9b7f4-b388-44ab-b379-4b0a42934d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_1280_0.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_1280_1280.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_1280_1920.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_1280_2560.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_1280_3200.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_1280_3840.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_1920_0.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_1920_1920.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_1920_640.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_2560_0.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_2560_1280.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_2560_1920.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_2560_640.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_3200_1280.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_3200_640.npy\n",
      "LT05_L1TP_129038_19860731_20170221_01_T1_patch_640_3840.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_1280_1280.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_1280_640.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_1920_0.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_1920_1920.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_1920_640.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_2560_1280.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_2560_640.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_3200_640.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_640_3200.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_640_3840.npy\n",
      "LT05_L1TP_129038_19870107_20170221_01_T1_patch_640_4480.npy\n",
      "LT05_L1TP_129038_19870920_20170418_01_T1_patch_2560_1280.npy\n",
      "LT05_L1TP_129038_19870920_20170418_01_T1_patch_640_3200.npy\n",
      "LT05_L1TP_129038_19870920_20170418_01_T1_patch_640_3840.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_1280_1280.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_1280_1920.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_1280_3840.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_1280_4480.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_1280_640.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_1920_0.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_1920_1280.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_1920_640.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_2560_640.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_640_3200.npy\n",
      "LT05_L1TP_129038_20070506_20161115_01_T1_patch_640_3840.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_1280_4480.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_1920_3840.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_1920_4480.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_1920_5120.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_2560_3200.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_2560_3840.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_2560_5120.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_3200_3840.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_3840_3200.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_3840_3840.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_3840_5120.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_4480_1920.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_4480_2560.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_4480_3200.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_5120_1920.npy\n",
      "LT05_L1TP_130038_19860807_20170221_01_T1_patch_5120_3200.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_1280_2560.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_1280_3200.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_1280_3840.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_2560_5760.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_3200_2560.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_3200_3200.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_3200_5760.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_3840_1920.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_3840_2560.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_3840_5120.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_4480_1920.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_4480_2560.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_4480_3200.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_4480_3840.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_4480_4480.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_5120_1280.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_5120_3200.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_5760_1280.npy\n",
      "LT05_L1TP_130038_19870725_20170320_01_T1_patch_5760_1920.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_1920_3840.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_1920_4480.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_1920_5120.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_2560_3200.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_2560_3840.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_2560_4480.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_2560_5120.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_3200_3840.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_3200_5120.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_3200_5760.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_3840_3200.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_3840_3840.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_3840_5760.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_4480_1920.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_4480_2560.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_4480_3200.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_4480_5120.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_5120_3200.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_5120_3840.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_5120_4480.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_5760_1280.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_5760_1920.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_5760_2560.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_5760_3200.npy\n",
      "LT05_L1TP_130038_19891205_20170214_01_T2_patch_5760_3840.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_1280_3840.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_1280_5120.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_1920_2560.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_1920_3200.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_1920_3840.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_1920_4480.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_1920_5120.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_2560_3200.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_2560_3840.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_2560_4480.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_2560_5120.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_2560_5760.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_3200_3200.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_3200_3840.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_3200_4480.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_3200_5120.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_3840_3200.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_3840_3840.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_3840_4480.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_3840_5120.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_3840_5760.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_4480_1920.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_4480_3200.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_4480_4480.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_4480_5120.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_5120_3200.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_5120_3840.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_5120_4480.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_5760_1280.npy\n",
      "LT05_L1TP_130038_20070918_20161111_01_T1_patch_5760_3200.npy\n",
      "LT05_L1TP_130039_19870725_20170320_01_T1_patch_1920_1280.npy\n",
      "LT05_L1TP_130039_19870725_20170320_01_T1_patch_2560_640.npy\n",
      "LT05_L1TP_130039_19870725_20170320_01_T1_patch_3200_1920.npy\n",
      "LT05_L1TP_130039_19870725_20170320_01_T1_patch_3840_1280.npy\n",
      "LT05_L1TP_130039_19870725_20170320_01_T1_patch_3840_1920.npy\n",
      "LT05_L1TP_130039_19870725_20170320_01_T1_patch_3840_640.npy\n",
      "LT05_L1TP_130039_19870725_20170320_01_T1_patch_4480_1280.npy\n",
      "LT05_L1TP_130039_19870725_20170320_01_T1_patch_4480_1920.npy\n",
      "LT05_L1TP_130039_19870725_20170320_01_T1_patch_4480_640.npy\n",
      "LT05_L1TP_130039_19880202_20170221_01_T1_patch_1920_1280.npy\n",
      "LT05_L1TP_130039_19880202_20170221_01_T1_patch_2560_1280.npy\n",
      "LT05_L1TP_130039_19880202_20170221_01_T1_patch_2560_640.npy\n",
      "LT05_L1TP_130039_19880202_20170221_01_T1_patch_3200_1280.npy\n",
      "LT05_L1TP_130039_19880202_20170221_01_T1_patch_3200_1920.npy\n",
      "LT05_L1TP_130039_19880202_20170221_01_T1_patch_3200_640.npy\n",
      "LT05_L1TP_130039_19880202_20170221_01_T1_patch_3840_1280.npy\n",
      "LT05_L1TP_130039_19880202_20170221_01_T1_patch_3840_1920.npy\n",
      "LT05_L1TP_130039_19880202_20170221_01_T1_patch_3840_640.npy\n",
      "LT05_L1TP_130039_19880202_20170221_01_T1_patch_4480_1280.npy\n",
      "LT05_L1TP_130039_20070918_20161111_01_T1_patch_2560_1280.npy\n",
      "LT05_L1TP_130039_20070918_20161111_01_T1_patch_2560_640.npy\n",
      "LT05_L1TP_130039_20070918_20161111_01_T1_patch_3200_1280.npy\n",
      "LT05_L1TP_130039_20070918_20161111_01_T1_patch_3200_1920.npy\n",
      "LT05_L1TP_130039_20070918_20161111_01_T1_patch_3840_1920.npy\n",
      "LT05_L1TP_130039_20070918_20161111_01_T1_patch_3840_640.npy\n",
      "LT05_L1TP_130039_20070918_20161111_01_T1_patch_4480_1920.npy\n",
      "LT05_L1TP_139041_20101230_20161011_01_T1_patch_3200_3200.npy\n",
      "LT05_L1TP_139041_20101230_20161011_01_T1_patch_3840_3200.npy\n",
      "LT05_L1TP_139041_20101230_20161011_01_T1_patch_3840_3840.npy\n",
      "LT05_L1TP_139041_20101230_20161011_01_T1_patch_4480_2560.npy\n",
      "LT05_L1TP_139041_20101230_20161011_01_T1_patch_4480_3200.npy\n",
      "LT05_L1TP_145039_19970118_20170101_01_T1_patch_1280_1920.npy\n",
      "LT05_L1TP_145039_19970118_20170101_01_T1_patch_1280_2560.npy\n",
      "LT05_L1TP_145039_19970118_20170101_01_T1_patch_1920_2560.npy\n",
      "LT05_L1TP_145039_19970118_20170101_01_T1_patch_1920_3200.npy\n",
      "LT05_L1TP_145039_19970118_20170101_01_T1_patch_2560_1920.npy\n",
      "LT05_L1TP_145039_19970118_20170101_01_T1_patch_2560_3200.npy\n",
      "LT05_L1TP_145039_19970118_20170101_01_T1_patch_3200_2560.npy\n",
      "LT05_L1TP_145039_20001228_20161213_01_T1_patch_1280_2560.npy\n",
      "LT05_L1TP_145039_20001228_20161213_01_T1_patch_1920_3200.npy\n",
      "LT05_L1TP_145039_20001228_20161213_01_T1_patch_2560_2560.npy\n",
      "LT05_L1TP_145039_20001228_20161213_01_T1_patch_2560_3200.npy\n",
      "LT05_L1TP_145039_20001228_20161213_01_T1_patch_3200_2560.npy\n",
      "LT05_L1TP_145039_20001228_20161213_01_T1_patch_3200_3200.npy\n"
     ]
    }
   ],
   "source": [
    "!ls /hdd/yuchen/satdata/landslides/train_numpy_images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8f5583-21ae-4d35-a69c-c79a0019afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('/hdd/yuchen/satdata/fmow-sentinel/train.csv', index_col=None)\n",
    "# split = 'train'\n",
    "# df['image_path'] = '/hdd/yuchen/satdata/fmow-sentinel/' + split + '/' + df['category'] + '/' + df['category'] + '_' + df['location_id'].astype(str) + '/' + df['category'] + '_' + df['location_id'].astype(str) + '_' + df['image_id'].astype(str) + '.tif'\n",
    "# df = df[['category', 'location_id', 'image_id', 'timestamp', 'polygon', 'image_path']]\n",
    "# df.to_csv('/hdd/yuchen/satdata/fmow-sentinel/train_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298646ac-7fe2-41e4-9f79-72eaf05626da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('/hdd/yuchen/satdata/fmow-sentinel/val.csv', index_col=None)\n",
    "# split = 'train'\n",
    "# df['image_path'] = '/hdd/yuchen/satdata/fmow-sentinel/' + split + '/' + df['category'] + '/' + df['category'] + '_' + df['location_id'].astype(str) + '/' + df['category'] + '_' + df['location_id'].astype(str) + '_' + df['image_id'].astype(str) + '.tif'\n",
    "# df = df[['category', 'location_id', 'image_id', 'timestamp', 'polygon', 'image_path']]\n",
    "# df.to_csv('/hdd/yuchen/satdata/fmow-sentinel/val_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796ab310-9c41-4264-a6e7-3483fa8723ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    batch_size = 64\n",
    "    epochs = 400\n",
    "    accum_iter = 1\n",
    "    model_type = 'group_c'  # ['group_c', 'temporal', 'vanilla']\n",
    "    model = 'mae_vit_large_patch16'\n",
    "    input_size = 224\n",
    "    patch_size = 16\n",
    "    mask_ratio = 0.75\n",
    "    spatial_mask = False  # Whether to mask all channels of a spatial location. Only for indp c model\n",
    "    norm_pix_loss = False   # Use (per-patch) normalized pixels as targets for computing loss\n",
    "    weight_decay = 0.05\n",
    "    lr = 1e-3\n",
    "    blr = 1e-3\n",
    "    min_lr = 0.\n",
    "    warmup_epochs = 40\n",
    "    train_path = '/hdd/yuchen/fmow-sentinel/train.csv'\n",
    "    dataset_type = 'sentinel'  # ['rgb', 'temporal', 'sentinel', 'euro_sat', 'naip']\n",
    "    masked_bands = None\n",
    "    dropped_bands = None\n",
    "    grouped_bands = []\n",
    "    output_dir = '/hdd/yuchen/SatMAE/temp'\n",
    "    log_dir = '/hdd/yuchen/SatMAE/temp'\n",
    "    device = 'cuda:0'\n",
    "    seed = 0\n",
    "    resume = ''\n",
    "    wandb = None\n",
    "    start_epoch = 0\n",
    "    num_workers = 10\n",
    "    pin_mem = True\n",
    "    no_pin_mem = True\n",
    "    world_size = 1\n",
    "    local_rank = os.getenv('LOCAL_RANK', 0)\n",
    "    dist_on_itp = True\n",
    "    dist_url = 'env://'\n",
    "    distributed = False\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac605e98-4385-4400-a6ae-a6d48d1cc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size =16 \n",
    "args.accum_iter =32 \n",
    "args.blr =0.0001 \n",
    "args.epochs =200 \n",
    "# args.warmup_epochs 20 \n",
    "args.num_workers =16 \n",
    "args.input_size =96 \n",
    "args.patch_size =8 \n",
    "args.mask_ratio =0.75 \n",
    "args.model_type ='group_c' \n",
    "args.dataset_type ='sentinel' \n",
    "args.dropped_bands =[0,9,10] \n",
    "args.grouped_bands = [[0, 1, 2, 6 ], [3, 4 ,5, 7 ], [8, 9 ]]\n",
    "\n",
    "args.train_path= '/hdd/yuchen/satdata/fmow-sentinel/train_.csv'\n",
    "args.output_dir ='/hdd/yuchen/SatMAE/temp'\n",
    "args.log_dir ='/hdd/yuchen/SatMAE/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e728c2-afb3-4d8a-8e4c-16c67dd1b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<util.datasets.SentinelIndividualImageDataset object at 0x7f5bc86bbdd0>\n",
      "<util.datasets.SentinelIndividualImageDataset object at 0x7f5bc86bbdd0>\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(args.device)\n",
    "\n",
    "seed = args.seed + misc.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "dataset_train = build_fmow_dataset(is_train=True, args=args)\n",
    "print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20dc854-6e5d-4888-94a6-0f626e8bc30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39785c5e-b22a-4c88-8ab1-1c0b75bf1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245ed0b6-96d0-49c2-a804-38b222510c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, sampler=sampler_train,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7d37d24-7688-40ba-a2b1-af7414640259",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping bands [[0, 1, 2, 6], [3, 4, 5, 7], [8, 9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MaskedAutoencoderGroupChannelViT(\n",
       "  (patch_embed): ModuleList(\n",
       "    (0): PatchEmbed(\n",
       "      (proj): Conv2d(4, 1024, kernel_size=(8, 8), stride=(8, 8))\n",
       "    )\n",
       "    (1): PatchEmbed(\n",
       "      (proj): Conv2d(4, 1024, kernel_size=(8, 8), stride=(8, 8))\n",
       "    )\n",
       "    (2): PatchEmbed(\n",
       "      (proj): Conv2d(2, 1024, kernel_size=(8, 8), stride=(8, 8))\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (decoder_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  (decoder_pred): ModuleList(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.model_type == 'group_c':\n",
    "        # Workaround because action append will add to default list\n",
    "    if len(args.grouped_bands) == 0:\n",
    "        args.grouped_bands = [[0, 1, 2, 6], [3, 4, 5, 7], [8, 9]]\n",
    "    print(f\"Grouping bands {args.grouped_bands}\")\n",
    "    model = models_mae_group_channels.__dict__[args.model](img_size=args.input_size,\n",
    "                                                               patch_size=args.patch_size,\n",
    "                                                               in_chans=dataset_train.in_c,\n",
    "                                                               channel_groups=args.grouped_bands,\n",
    "                                                               spatial_mask=args.spatial_mask,\n",
    "                                                               norm_pix_loss=args.norm_pix_loss)\n",
    "elif args.model_type == 'temporal':\n",
    "    model = models_mae_temporal.__dict__[args.model](norm_pix_loss=args.norm_pix_loss)\n",
    "    # non-spatial, non-temporal\n",
    "else:\n",
    "    model = models_mae.__dict__[args.model](img_size=args.input_size,\n",
    "                                                patch_size=args.patch_size,\n",
    "                                                in_chans=dataset_train.in_c,\n",
    "                                                norm_pix_loss=args.norm_pix_loss)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9dd2d16-4936-48c4-9311-4be56eb58542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base lr: 1.00e-04\n",
      "actual lr: 2.00e-04\n",
      "accumulate grad iterations: 32\n",
      "effective batch size: 512\n"
     ]
    }
   ],
   "source": [
    "model_without_ddp = model\n",
    "# print(\"Model = %s\" % str(model_without_ddp))\n",
    "\n",
    "eff_batch_size = args.batch_size * args.accum_iter * misc.get_world_size()\n",
    "\n",
    "if args.lr is None:  # only base_lr is specified\n",
    "    args.lr = args.blr * eff_batch_size / 256\n",
    "\n",
    "print(\"base lr: %.2e\" % (args.lr * 256 / eff_batch_size))\n",
    "print(\"actual lr: %.2e\" % args.lr)\n",
    "\n",
    "print(\"accumulate grad iterations: %d\" % args.accum_iter)\n",
    "print(\"effective batch size: %d\" % eff_batch_size)\n",
    "\n",
    "if args.distributed:\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], find_unused_parameters=True)\n",
    "    model_without_ddp = model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d1c353b-8b40-41cc-9a75-123d1977371e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0002\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0002\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "param_groups = optim_factory.add_weight_decay(model_without_ddp, args.weight_decay)\n",
    "optimizer = torch.optim.AdamW(param_groups, lr=args.lr, betas=(0.9, 0.95))\n",
    "print(optimizer)\n",
    "loss_scaler = NativeScaler()\n",
    "\n",
    "misc.load_model(args=args, model_without_ddp=model_without_ddp, optimizer=optimizer, loss_scaler=loss_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abbdef3e-ab9b-45c6-aa0c-d387047dcb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 200 epochs\n",
      "Epoch: [0]  [    0/44554]  eta: 1 day, 21:33:25  lr: 0.000000  loss: 1.9367 (1.9367)  time: 3.6811  data: 2.0113  max mem: 7450\n",
      "Epoch: [0]  [   20/44554]  eta: 4:09:57  lr: 0.000000  loss: 1.8957 (1.8945)  time: 0.1696  data: 0.0003  max mem: 8696\n",
      "Epoch: [0]  [   40/44554]  eta: 3:11:29  lr: 0.000000  loss: 1.8834 (1.8906)  time: 0.1755  data: 0.0003  max mem: 11169\n",
      "Epoch: [0]  [   60/44554]  eta: 2:49:59  lr: 0.000000  loss: 1.8802 (1.8895)  time: 0.1700  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [   80/44554]  eta: 2:39:40  lr: 0.000000  loss: 1.8835 (1.8883)  time: 0.1733  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  100/44554]  eta: 2:33:19  lr: 0.000000  loss: 1.8810 (1.8866)  time: 0.1726  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  120/44554]  eta: 2:28:52  lr: 0.000000  loss: 1.8900 (1.8870)  time: 0.1711  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  140/44554]  eta: 2:25:57  lr: 0.000000  loss: 1.8859 (1.8865)  time: 0.1740  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  160/44554]  eta: 2:23:52  lr: 0.000000  loss: 1.8887 (1.8867)  time: 0.1752  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  180/44554]  eta: 2:21:54  lr: 0.000000  loss: 1.8523 (1.8840)  time: 0.1712  data: 0.0003  max mem: 11169\n",
      "Epoch: [0]  [  200/44554]  eta: 2:20:34  lr: 0.000000  loss: 1.8733 (1.8830)  time: 0.1745  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  220/44554]  eta: 2:19:16  lr: 0.000000  loss: 1.8538 (1.8821)  time: 0.1717  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  240/44554]  eta: 2:18:20  lr: 0.000000  loss: 1.8696 (1.8823)  time: 0.1745  data: 0.0003  max mem: 11169\n",
      "Epoch: [0]  [  260/44554]  eta: 2:17:32  lr: 0.000000  loss: 1.8803 (1.8828)  time: 0.1742  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  280/44554]  eta: 2:16:39  lr: 0.000000  loss: 1.8689 (1.8820)  time: 0.1705  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  300/44554]  eta: 2:16:03  lr: 0.000000  loss: 1.8706 (1.8817)  time: 0.1743  data: 0.0003  max mem: 11169\n",
      "Epoch: [0]  [  320/44554]  eta: 2:15:29  lr: 0.000000  loss: 1.8777 (1.8811)  time: 0.1735  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  340/44554]  eta: 2:14:56  lr: 0.000000  loss: 1.8653 (1.8802)  time: 0.1722  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  360/44554]  eta: 2:14:31  lr: 0.000000  loss: 1.8622 (1.8796)  time: 0.1745  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  380/44554]  eta: 2:14:03  lr: 0.000000  loss: 1.8485 (1.8790)  time: 0.1724  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  400/44554]  eta: 2:13:45  lr: 0.000000  loss: 1.8492 (1.8779)  time: 0.1752  data: 0.0003  max mem: 11169\n",
      "Epoch: [0]  [  420/44554]  eta: 2:13:26  lr: 0.000000  loss: 1.8643 (1.8773)  time: 0.1746  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  440/44554]  eta: 2:13:04  lr: 0.000000  loss: 1.8498 (1.8763)  time: 0.1724  data: 0.0003  max mem: 11169\n",
      "Epoch: [0]  [  460/44554]  eta: 2:12:49  lr: 0.000000  loss: 1.8510 (1.8754)  time: 0.1751  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  480/44554]  eta: 2:12:36  lr: 0.000000  loss: 1.8545 (1.8745)  time: 0.1752  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  500/44554]  eta: 2:12:16  lr: 0.000000  loss: 1.8590 (1.8736)  time: 0.1716  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  520/44554]  eta: 2:12:04  lr: 0.000000  loss: 1.8612 (1.8732)  time: 0.1752  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  540/44554]  eta: 2:11:47  lr: 0.000000  loss: 1.8485 (1.8726)  time: 0.1715  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  560/44554]  eta: 2:11:38  lr: 0.000000  loss: 1.8231 (1.8714)  time: 0.1763  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  580/44554]  eta: 2:11:28  lr: 0.000000  loss: 1.8365 (1.8705)  time: 0.1755  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  600/44554]  eta: 2:11:15  lr: 0.000000  loss: 1.8340 (1.8694)  time: 0.1724  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  620/44554]  eta: 2:11:05  lr: 0.000000  loss: 1.8414 (1.8683)  time: 0.1748  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  640/44554]  eta: 2:10:56  lr: 0.000000  loss: 1.8132 (1.8668)  time: 0.1748  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  660/44554]  eta: 2:10:43  lr: 0.000000  loss: 1.8154 (1.8654)  time: 0.1720  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  680/44554]  eta: 2:10:35  lr: 0.000000  loss: 1.8327 (1.8646)  time: 0.1754  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  700/44554]  eta: 2:10:23  lr: 0.000000  loss: 1.8355 (1.8635)  time: 0.1716  data: 0.0002  max mem: 11169\n",
      "Epoch: [0]  [  720/44554]  eta: 2:10:15  lr: 0.000000  loss: 1.8098 (1.8623)  time: 0.1748  data: 0.0002  max mem: 11169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'rasterio._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/logging/__init__.py\", line 1928, in getLogger\n",
      "    def getLogger(name=None):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-04dbb89816d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlog_writer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/SatMAE/engine_pretrain.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, data_loader, optimizer, device, epoch, loss_scaler, log_writer, args)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/SatMAE/models_mae_group_channels.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, imgs, mask_ratio)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_restore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_restore\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [N, C, L, p*p]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/SatMAE/models_mae_group_channels.py\u001b[0m in \u001b[0;36mforward_loss\u001b[0;34m(self, imgs, pred, mask)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_removed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mgroup_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (N, L)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgroup_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mnum_removed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# mean loss on removed patches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    print(f\"Start training for {args.epochs} epochs\")\n",
    "    start_time = time.time()\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            data_loader_train.sampler.set_epoch(epoch)\n",
    "\n",
    "        if args.model_type == 'temporal':\n",
    "            train_stats = train_one_epoch_temporal(\n",
    "                model, data_loader_train,\n",
    "                optimizer, device, epoch, loss_scaler,\n",
    "                log_writer=log_writer,\n",
    "                args=args\n",
    "            )\n",
    "        else:\n",
    "            train_stats = train_one_epoch(\n",
    "                model, data_loader_train,\n",
    "                optimizer, device, epoch, loss_scaler,\n",
    "                log_writer=log_writer,\n",
    "                args=args\n",
    "            )\n",
    "\n",
    "        if args.output_dir and (epoch % 5 == 0 or epoch + 1 == args.epochs):\n",
    "            misc.save_model(\n",
    "                args=args, model=model, model_without_ddp=model_without_ddp, optimizer=optimizer,\n",
    "                loss_scaler=loss_scaler, epoch=epoch)\n",
    "\n",
    "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "                     'epoch': epoch, }\n",
    "\n",
    "        if args.output_dir and misc.is_main_process():\n",
    "            if log_writer is not None:\n",
    "                log_writer.flush()\n",
    "            with open(os.path.join(args.output_dir, \"log.txt\"), mode=\"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "            try:\n",
    "                wandb.log(log_stats)\n",
    "            except ValueError:\n",
    "                print(f\"Invalid stats?\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d38de5-3198-4371-bf95-6ec57fe11c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e19c95-1902-4d3a-aa6a-0f9f19753e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60356269-0ac2-4f58-9dde-ab49c56db7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d61d33-1594-4bed-a624-1abd10a181ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import timm\n",
    "\n",
    "assert timm.__version__ == \"0.3.2\"  # version check\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "\n",
    "import util.lr_decay as lrd\n",
    "import util.misc as misc\n",
    "from util.datasets import build_fmow_dataset\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "\n",
    "import models_resnet\n",
    "import models_vit\n",
    "import models_vit_temporal\n",
    "import models_vit_group_channels\n",
    "\n",
    "from engine_finetune import (train_one_epoch, train_one_epoch_temporal,\n",
    "                             evaluate, evaluate_temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efeb5625-10b5-4984-ae54-de47a97ba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    batch_size =64,\n",
    "    epochs =50\n",
    "    accum_iter =1\n",
    "    model_type = None  # ['group_c', 'resnet', 'resnet_pre', 'temporal', 'vanilla'],\n",
    "    model = 'vit_large_patch16'\n",
    "    input_size = 224\n",
    "    patch_size = 16\n",
    "    drop_path = 0.1\n",
    "    clip_grad = None\n",
    "    weight_decay = 0.05\n",
    "    lr = 1e-3\n",
    "    blr = 1e-3\n",
    "    layer_decay = 0.75\n",
    "    min_lr = 1e-6\n",
    "    warmup_epochs = 5\n",
    "    \n",
    "    color_jitter = None\n",
    "    aa = 'rand-m9-mstd0.5-inc1'\n",
    "    smoothing = 0.1\n",
    "    reprob = 0.25\n",
    "    remode = 'pixel'\n",
    "    recount = 1\n",
    "    resplit = True\n",
    "    mixup = 0\n",
    "    cutmix = 0\n",
    "    cutmix_minmax = None\n",
    "    mixup_prob = 1\n",
    "    mixup_switch_prob = 0.5\n",
    "    mixup_mode = 'batch'\n",
    "    finetune = ''\n",
    "    global_pool = True\n",
    "    cls_token = False\n",
    "    train_path='/home/train_62classes.csv'\n",
    "    test_path = '/home/train_62classes.csv'\n",
    "    dataset_type = 'sentinel'\n",
    "    masked_bands = None\n",
    "    dropped_bands = None\n",
    "    grouped_bands = []\n",
    "    nb_classes = 62\n",
    "    output_dir =  '/hdd/yuchen/SatMAE/temp'\n",
    "    log_dir = '/hdd/yuchen/SatMAE/temp'\n",
    "    device = 'cuda:0'\n",
    "    seed = 0\n",
    "    resume = ''\n",
    "    save_every = 1\n",
    "    wandb = None\n",
    "    start_epoch = 0\n",
    "    eval = False\n",
    "    dist_eval = False\n",
    "    num_workers = 10\n",
    "    pin_mem = False\n",
    "    no_pin_mem = True\n",
    "    world_size = 1\n",
    "    local_rank = os.getenv('LOCAL_RANK', 0)\n",
    "    dist_on_itp = True\n",
    "    dist_url = 'env://'\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f9f72a-28ba-4952-bf17-3c469ec48956",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.nproc_per_node=8 \n",
    "args.batch_size =8 \n",
    "args.accum_iter =16 \n",
    "args.blr =0.0002 \n",
    "args.epochs =30 \n",
    "args.num_workers =16 \n",
    "args.input_size =96 \n",
    "args.patch_size =8  \n",
    "args.weight_decay = 0.05 \n",
    "args.drop_path  =0.2 \n",
    "args.reprob  =0.25 \n",
    "args.mixup = 0.8 \n",
    "args.cutmix = 1.0 \n",
    "args.model_type = 'group_c'  \n",
    "args.dataset_type = 'sentinel' \n",
    "args.dropped_bands = [0, 9, 10] \n",
    "args.train_path = '/hdd/yuchen/satdata/fmow-sentinel/train_.csv'\n",
    "args.test_path = '/hdd/yuchen/satdata/fmow-sentinel/train_.csv' \n",
    "args.output_dir = '/hdd/yuchen/SatMAE/temp'\n",
    "args.log_dir = '/hdd/yuchen/SatMAE/temp'\n",
    "args.finetune = '/hdd/yuchen/satdata/weights/pretrain-vit-large-e199.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a112a-20eb-47b0-94ef-269c8a729a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd919f2e-aed0-46ba-86cd-4b5901f9f55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13396d53-18e9-4e73-9da3-56320ccde4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<util.datasets.SentinelIndividualImageDataset object at 0x7fcea5f29290>\n",
      "<util.datasets.SentinelIndividualImageDataset object at 0x7fceb2fbc790>\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(args.device)\n",
    "\n",
    "    # fix the seed for reproducibility\n",
    "seed = args.seed + misc.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "dataset_train = build_fmow_dataset(is_train=True, args=args)\n",
    "dataset_val = build_fmow_dataset(is_train=False, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43479bc5-4da6-48d8-8d32-8ccd7bff9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "sampler_val = torch.utils.data.SequentialSampler(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21841ab6-a9f4-4e35-9c23-934431e1270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5398aa9-d3ea-4ec8-9aeb-802acbc75a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixup is activated!\n"
     ]
    }
   ],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, sampler=sampler_train,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val, sampler=sampler_val,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "mixup_fn = None\n",
    "mixup_active = args.mixup > 0 or args.cutmix > 0. or args.cutmix_minmax is not None\n",
    "if mixup_active:\n",
    "    print(\"Mixup is activated!\")\n",
    "    mixup_fn = Mixup(\n",
    "            mixup_alpha=args.mixup, cutmix_alpha=args.cutmix, cutmix_minmax=args.cutmix_minmax,\n",
    "            prob=args.mixup_prob, switch_prob=args.mixup_switch_prob, mode=args.mixup_mode,\n",
    "            label_smoothing=args.smoothing, num_classes=args.nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d11cb4-c9aa-4dbb-827e-08223c720a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_loader_val:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "783fbb0a-36a6-41b4-90d2-49c9d15f6470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping bands [[0, 1, 2, 6], [3, 4, 5, 7], [8, 9]]\n"
     ]
    }
   ],
   "source": [
    "if args.model_type == 'group_c':\n",
    "        # Workaround because action append will add to default list\n",
    "    if len(args.grouped_bands) == 0:\n",
    "        args.grouped_bands = [[0, 1, 2, 6], [3, 4, 5, 7], [8, 9]]\n",
    "    print(f\"Grouping bands {args.grouped_bands}\")\n",
    "    model = models_vit_group_channels.__dict__[args.model](\n",
    "            patch_size=args.patch_size, img_size=args.input_size, in_chans=dataset_train.in_c,\n",
    "            channel_groups=args.grouped_bands,\n",
    "            num_classes=args.nb_classes, drop_path_rate=args.drop_path, global_pool=args.global_pool,\n",
    "        )\n",
    "elif args.model_type == 'resnet' or args.model_type == 'resnet_pre':\n",
    "    pre_trained = args.model_type == 'resnet_pre'\n",
    "    model = models_resnet.__dict__[args.model](in_c=dataset_train.in_c, pretrained=pre_trained)\n",
    "elif args.model_type == 'temporal':\n",
    "    model = models_vit_temporal.__dict__[args.model](\n",
    "            num_classes=args.nb_classes,\n",
    "            drop_path_rate=args.drop_path,\n",
    "            global_pool=args.global_pool,\n",
    "    )\n",
    "else:\n",
    "    model = models_vit.__dict__[args.model](\n",
    "            patch_size=args.patch_size, img_size=args.input_size, in_chans=dataset_train.in_c,\n",
    "            num_classes=args.nb_classes, drop_path_rate=args.drop_path, global_pool=args.global_pool,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47948d13-12ac-4e9d-ae23-db7e58dfd97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eval = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f873a8-5fca-4d0f-af2f-646b5a383e63",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained checkpoint from: /hdd/yuchen/satdata/weights/pretrain-vit-large-e199.pth\n",
      "_IncompatibleKeys(missing_keys=['channel_cls_embed', 'head.weight', 'head.bias', 'fc_norm.weight', 'fc_norm.bias'], unexpected_keys=['mask_token', 'decoder_pos_embed', 'decoder_channel_embed', 'norm.weight', 'norm.bias', 'decoder_embed.weight', 'decoder_embed.bias', 'decoder_blocks.0.norm1.weight', 'decoder_blocks.0.norm1.bias', 'decoder_blocks.0.attn.qkv.weight', 'decoder_blocks.0.attn.qkv.bias', 'decoder_blocks.0.attn.proj.weight', 'decoder_blocks.0.attn.proj.bias', 'decoder_blocks.0.norm2.weight', 'decoder_blocks.0.norm2.bias', 'decoder_blocks.0.mlp.fc1.weight', 'decoder_blocks.0.mlp.fc1.bias', 'decoder_blocks.0.mlp.fc2.weight', 'decoder_blocks.0.mlp.fc2.bias', 'decoder_blocks.1.norm1.weight', 'decoder_blocks.1.norm1.bias', 'decoder_blocks.1.attn.qkv.weight', 'decoder_blocks.1.attn.qkv.bias', 'decoder_blocks.1.attn.proj.weight', 'decoder_blocks.1.attn.proj.bias', 'decoder_blocks.1.norm2.weight', 'decoder_blocks.1.norm2.bias', 'decoder_blocks.1.mlp.fc1.weight', 'decoder_blocks.1.mlp.fc1.bias', 'decoder_blocks.1.mlp.fc2.weight', 'decoder_blocks.1.mlp.fc2.bias', 'decoder_blocks.2.norm1.weight', 'decoder_blocks.2.norm1.bias', 'decoder_blocks.2.attn.qkv.weight', 'decoder_blocks.2.attn.qkv.bias', 'decoder_blocks.2.attn.proj.weight', 'decoder_blocks.2.attn.proj.bias', 'decoder_blocks.2.norm2.weight', 'decoder_blocks.2.norm2.bias', 'decoder_blocks.2.mlp.fc1.weight', 'decoder_blocks.2.mlp.fc1.bias', 'decoder_blocks.2.mlp.fc2.weight', 'decoder_blocks.2.mlp.fc2.bias', 'decoder_blocks.3.norm1.weight', 'decoder_blocks.3.norm1.bias', 'decoder_blocks.3.attn.qkv.weight', 'decoder_blocks.3.attn.qkv.bias', 'decoder_blocks.3.attn.proj.weight', 'decoder_blocks.3.attn.proj.bias', 'decoder_blocks.3.norm2.weight', 'decoder_blocks.3.norm2.bias', 'decoder_blocks.3.mlp.fc1.weight', 'decoder_blocks.3.mlp.fc1.bias', 'decoder_blocks.3.mlp.fc2.weight', 'decoder_blocks.3.mlp.fc2.bias', 'decoder_blocks.4.norm1.weight', 'decoder_blocks.4.norm1.bias', 'decoder_blocks.4.attn.qkv.weight', 'decoder_blocks.4.attn.qkv.bias', 'decoder_blocks.4.attn.proj.weight', 'decoder_blocks.4.attn.proj.bias', 'decoder_blocks.4.norm2.weight', 'decoder_blocks.4.norm2.bias', 'decoder_blocks.4.mlp.fc1.weight', 'decoder_blocks.4.mlp.fc1.bias', 'decoder_blocks.4.mlp.fc2.weight', 'decoder_blocks.4.mlp.fc2.bias', 'decoder_blocks.5.norm1.weight', 'decoder_blocks.5.norm1.bias', 'decoder_blocks.5.attn.qkv.weight', 'decoder_blocks.5.attn.qkv.bias', 'decoder_blocks.5.attn.proj.weight', 'decoder_blocks.5.attn.proj.bias', 'decoder_blocks.5.norm2.weight', 'decoder_blocks.5.norm2.bias', 'decoder_blocks.5.mlp.fc1.weight', 'decoder_blocks.5.mlp.fc1.bias', 'decoder_blocks.5.mlp.fc2.weight', 'decoder_blocks.5.mlp.fc2.bias', 'decoder_blocks.6.norm1.weight', 'decoder_blocks.6.norm1.bias', 'decoder_blocks.6.attn.qkv.weight', 'decoder_blocks.6.attn.qkv.bias', 'decoder_blocks.6.attn.proj.weight', 'decoder_blocks.6.attn.proj.bias', 'decoder_blocks.6.norm2.weight', 'decoder_blocks.6.norm2.bias', 'decoder_blocks.6.mlp.fc1.weight', 'decoder_blocks.6.mlp.fc1.bias', 'decoder_blocks.6.mlp.fc2.weight', 'decoder_blocks.6.mlp.fc2.bias', 'decoder_blocks.7.norm1.weight', 'decoder_blocks.7.norm1.bias', 'decoder_blocks.7.attn.qkv.weight', 'decoder_blocks.7.attn.qkv.bias', 'decoder_blocks.7.attn.proj.weight', 'decoder_blocks.7.attn.proj.bias', 'decoder_blocks.7.norm2.weight', 'decoder_blocks.7.norm2.bias', 'decoder_blocks.7.mlp.fc1.weight', 'decoder_blocks.7.mlp.fc1.bias', 'decoder_blocks.7.mlp.fc2.weight', 'decoder_blocks.7.mlp.fc2.bias', 'decoder_norm.weight', 'decoder_norm.bias', 'decoder_pred.0.weight', 'decoder_pred.0.bias', 'decoder_pred.1.weight', 'decoder_pred.1.bias', 'decoder_pred.2.weight', 'decoder_pred.2.bias'])\n",
      "{'channel_cls_embed', 'fc_norm.weight', 'fc_norm.bias', 'head.bias', 'head.weight'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GroupChannelsVisionTransformer(\n",
       "  (patch_embed): ModuleList(\n",
       "    (0): PatchEmbed(\n",
       "      (proj): Conv2d(4, 1024, kernel_size=(8, 8), stride=(8, 8))\n",
       "    )\n",
       "    (1): PatchEmbed(\n",
       "      (proj): Conv2d(4, 1024, kernel_size=(8, 8), stride=(8, 8))\n",
       "    )\n",
       "    (2): PatchEmbed(\n",
       "      (proj): Conv2d(2, 1024, kernel_size=(8, 8), stride=(8, 8))\n",
       "    )\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Linear(in_features=1024, out_features=62, bias=True)\n",
       "  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.finetune and not args.eval:\n",
    "    checkpoint = torch.load(args.finetune, map_location='cpu')\n",
    "\n",
    "    print(\"Load pre-trained checkpoint from: %s\" % args.finetune)\n",
    "    checkpoint_model = checkpoint['model']\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "\n",
    "    for k in ['pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'head.weight', 'head.bias']:\n",
    "        if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "            print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "            del checkpoint_model[k]\n",
    "\n",
    "    # interpolate position embedding\n",
    "    interpolate_pos_embed(model, checkpoint_model)\n",
    "\n",
    "    # load pre-trained model\n",
    "    msg = model.load_state_dict(checkpoint_model, strict=False)\n",
    "    print(msg)\n",
    "\n",
    "    # TODO: change assert msg based on patch_embed\n",
    "    if args.global_pool:\n",
    "        print(set(msg.missing_keys))\n",
    "            # assert set(msg.missing_keys) == {'head.weight', 'head.bias', 'fc_norm.weight', 'fc_norm.bias'}\n",
    "    else:\n",
    "        print(set(msg.missing_keys))\n",
    "            # assert set(msg.missing_keys) == {'head.weight', 'head.bias'}\n",
    "\n",
    "        # manually initialize fc layer\n",
    "    trunc_normal_(model.head.weight, std=2e-5)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dcda3ac-427f-4316-bca5-de03c1baa4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['channel_cls_embed', 'head.weight', 'head.bias', 'fc_norm.weight', 'fc_norm.bias'], unexpected_keys=['mask_token', 'decoder_pos_embed', 'decoder_channel_embed', 'norm.weight', 'norm.bias', 'decoder_embed.weight', 'decoder_embed.bias', 'decoder_blocks.0.norm1.weight', 'decoder_blocks.0.norm1.bias', 'decoder_blocks.0.attn.qkv.weight', 'decoder_blocks.0.attn.qkv.bias', 'decoder_blocks.0.attn.proj.weight', 'decoder_blocks.0.attn.proj.bias', 'decoder_blocks.0.norm2.weight', 'decoder_blocks.0.norm2.bias', 'decoder_blocks.0.mlp.fc1.weight', 'decoder_blocks.0.mlp.fc1.bias', 'decoder_blocks.0.mlp.fc2.weight', 'decoder_blocks.0.mlp.fc2.bias', 'decoder_blocks.1.norm1.weight', 'decoder_blocks.1.norm1.bias', 'decoder_blocks.1.attn.qkv.weight', 'decoder_blocks.1.attn.qkv.bias', 'decoder_blocks.1.attn.proj.weight', 'decoder_blocks.1.attn.proj.bias', 'decoder_blocks.1.norm2.weight', 'decoder_blocks.1.norm2.bias', 'decoder_blocks.1.mlp.fc1.weight', 'decoder_blocks.1.mlp.fc1.bias', 'decoder_blocks.1.mlp.fc2.weight', 'decoder_blocks.1.mlp.fc2.bias', 'decoder_blocks.2.norm1.weight', 'decoder_blocks.2.norm1.bias', 'decoder_blocks.2.attn.qkv.weight', 'decoder_blocks.2.attn.qkv.bias', 'decoder_blocks.2.attn.proj.weight', 'decoder_blocks.2.attn.proj.bias', 'decoder_blocks.2.norm2.weight', 'decoder_blocks.2.norm2.bias', 'decoder_blocks.2.mlp.fc1.weight', 'decoder_blocks.2.mlp.fc1.bias', 'decoder_blocks.2.mlp.fc2.weight', 'decoder_blocks.2.mlp.fc2.bias', 'decoder_blocks.3.norm1.weight', 'decoder_blocks.3.norm1.bias', 'decoder_blocks.3.attn.qkv.weight', 'decoder_blocks.3.attn.qkv.bias', 'decoder_blocks.3.attn.proj.weight', 'decoder_blocks.3.attn.proj.bias', 'decoder_blocks.3.norm2.weight', 'decoder_blocks.3.norm2.bias', 'decoder_blocks.3.mlp.fc1.weight', 'decoder_blocks.3.mlp.fc1.bias', 'decoder_blocks.3.mlp.fc2.weight', 'decoder_blocks.3.mlp.fc2.bias', 'decoder_blocks.4.norm1.weight', 'decoder_blocks.4.norm1.bias', 'decoder_blocks.4.attn.qkv.weight', 'decoder_blocks.4.attn.qkv.bias', 'decoder_blocks.4.attn.proj.weight', 'decoder_blocks.4.attn.proj.bias', 'decoder_blocks.4.norm2.weight', 'decoder_blocks.4.norm2.bias', 'decoder_blocks.4.mlp.fc1.weight', 'decoder_blocks.4.mlp.fc1.bias', 'decoder_blocks.4.mlp.fc2.weight', 'decoder_blocks.4.mlp.fc2.bias', 'decoder_blocks.5.norm1.weight', 'decoder_blocks.5.norm1.bias', 'decoder_blocks.5.attn.qkv.weight', 'decoder_blocks.5.attn.qkv.bias', 'decoder_blocks.5.attn.proj.weight', 'decoder_blocks.5.attn.proj.bias', 'decoder_blocks.5.norm2.weight', 'decoder_blocks.5.norm2.bias', 'decoder_blocks.5.mlp.fc1.weight', 'decoder_blocks.5.mlp.fc1.bias', 'decoder_blocks.5.mlp.fc2.weight', 'decoder_blocks.5.mlp.fc2.bias', 'decoder_blocks.6.norm1.weight', 'decoder_blocks.6.norm1.bias', 'decoder_blocks.6.attn.qkv.weight', 'decoder_blocks.6.attn.qkv.bias', 'decoder_blocks.6.attn.proj.weight', 'decoder_blocks.6.attn.proj.bias', 'decoder_blocks.6.norm2.weight', 'decoder_blocks.6.norm2.bias', 'decoder_blocks.6.mlp.fc1.weight', 'decoder_blocks.6.mlp.fc1.bias', 'decoder_blocks.6.mlp.fc2.weight', 'decoder_blocks.6.mlp.fc2.bias', 'decoder_blocks.7.norm1.weight', 'decoder_blocks.7.norm1.bias', 'decoder_blocks.7.attn.qkv.weight', 'decoder_blocks.7.attn.qkv.bias', 'decoder_blocks.7.attn.proj.weight', 'decoder_blocks.7.attn.proj.bias', 'decoder_blocks.7.norm2.weight', 'decoder_blocks.7.norm2.bias', 'decoder_blocks.7.mlp.fc1.weight', 'decoder_blocks.7.mlp.fc1.bias', 'decoder_blocks.7.mlp.fc2.weight', 'decoder_blocks.7.mlp.fc2.bias', 'decoder_norm.weight', 'decoder_norm.bias', 'decoder_pred.0.weight', 'decoder_pred.0.bias', 'decoder_pred.1.weight', 'decoder_pred.1.bias', 'decoder_pred.2.weight', 'decoder_pred.2.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint_model, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85ed7929-fbf2-4c35-aeda-a155f33395a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_ddp = model\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92afeb63-7c35-49cc-a5b4-2225274f07a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = GroupChannelsVisionTransformer(\n",
      "  (patch_embed): ModuleList(\n",
      "    (0): PatchEmbed(\n",
      "      (proj): Conv2d(4, 1024, kernel_size=(8, 8), stride=(8, 8))\n",
      "    )\n",
      "    (1): PatchEmbed(\n",
      "      (proj): Conv2d(4, 1024, kernel_size=(8, 8), stride=(8, 8))\n",
      "    )\n",
      "    (2): PatchEmbed(\n",
      "      (proj): Conv2d(2, 1024, kernel_size=(8, 8), stride=(8, 8))\n",
      "    )\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (12): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (13): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (14): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (15): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (16): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (17): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (18): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (19): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (20): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (21): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (22): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (23): Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=1024, out_features=62, bias=True)\n",
      "  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      ")\n",
      "number of params (M): 303.15\n",
      "base lr: 2.00e-03\n",
      "actual lr: 1.00e-03\n",
      "accumulate grad iterations: 16\n",
      "effective batch size: 128\n"
     ]
    }
   ],
   "source": [
    "    print(\"Model = %s\" % str(model_without_ddp))\n",
    "    print('number of params (M): %.2f' % (n_parameters / 1.e6))\n",
    "\n",
    "    eff_batch_size = args.batch_size * args.accum_iter * misc.get_world_size()\n",
    "\n",
    "    if args.lr is None:  # only base_lr is specified\n",
    "        args.lr = args.blr * eff_batch_size / 256\n",
    "\n",
    "    print(\"base lr: %.2e\" % (args.lr * 256 / eff_batch_size))\n",
    "    print(\"actual lr: %.2e\" % args.lr)\n",
    "\n",
    "    print(\"accumulate grad iterations: %d\" % args.accum_iter)\n",
    "    print(\"effective batch size: %d\" % eff_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bd3b354-8a87-4bb0-97d9-ef701988d983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = SoftTargetCrossEntropy()\n"
     ]
    }
   ],
   "source": [
    "    # build optimizer with layer-wise lr decay (lrd)\n",
    "    if args.model_type is not None and args.model_type.startswith('resnet'):\n",
    "        param_groups = model_without_ddp.parameters()\n",
    "    else:\n",
    "        param_groups = lrd.param_groups_lrd(model_without_ddp, args.weight_decay,\n",
    "                                            no_weight_decay_list=model_without_ddp.no_weight_decay(),\n",
    "                                            layer_decay=args.layer_decay)\n",
    "    optimizer = torch.optim.AdamW(param_groups, lr=args.lr)\n",
    "    loss_scaler = NativeScaler()\n",
    "\n",
    "    if mixup_fn is not None:\n",
    "        # smoothing is handled with mixup label transform\n",
    "        criterion = SoftTargetCrossEntropy()\n",
    "    elif args.smoothing > 0.:\n",
    "        criterion = LabelSmoothingCrossEntropy(smoothing=args.smoothing)\n",
    "    else:\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"criterion = %s\" % str(criterion))\n",
    "\n",
    "    misc.load_model(args=args, model_without_ddp=model_without_ddp, optimizer=optimizer, loss_scaler=loss_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eda6766e-2d07-41be-946b-fe5a2716b787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cf8b455-13c2-4485-9000-dde937303bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 30 epochs\n",
      "Epoch: [0]  [    0/89109]  eta: 3 days, 7:54:39  lr: 0.000000  loss: 4.1270 (4.1270)  time: 3.2284  data: 2.0287  max mem: 8178\n",
      "Epoch: [0]  [   20/89109]  eta: 9:00:04  lr: 0.000000  loss: 4.1271 (4.1271)  time: 0.2205  data: 0.0011  max mem: 11565\n",
      "Epoch: [0]  [   40/89109]  eta: 7:15:13  lr: 0.000000  loss: 4.1270 (4.1271)  time: 0.2191  data: 0.0007  max mem: 11565\n",
      "Epoch: [0]  [   60/89109]  eta: 6:37:21  lr: 0.000000  loss: 4.1270 (4.1270)  time: 0.2156  data: 0.0014  max mem: 11565\n",
      "Epoch: [0]  [   80/89109]  eta: 6:20:41  lr: 0.000000  loss: 4.1269 (4.1270)  time: 0.2225  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  100/89109]  eta: 6:10:02  lr: 0.000000  loss: 4.1270 (4.1270)  time: 0.2206  data: 0.0014  max mem: 11565\n",
      "Epoch: [0]  [  120/89109]  eta: 6:01:57  lr: 0.000000  loss: 4.1271 (4.1270)  time: 0.2168  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  140/89109]  eta: 5:57:03  lr: 0.000000  loss: 4.1269 (4.1270)  time: 0.2211  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  160/89109]  eta: 5:53:46  lr: 0.000000  loss: 4.1269 (4.1270)  time: 0.2235  data: 0.0016  max mem: 11565\n",
      "Epoch: [0]  [  180/89109]  eta: 5:50:49  lr: 0.000000  loss: 4.1269 (4.1270)  time: 0.2211  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  200/89109]  eta: 5:47:52  lr: 0.000000  loss: 4.1270 (4.1270)  time: 0.2172  data: 0.0016  max mem: 11565\n",
      "Epoch: [0]  [  220/89109]  eta: 5:45:56  lr: 0.000000  loss: 4.1268 (4.1270)  time: 0.2210  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  240/89109]  eta: 5:44:37  lr: 0.000001  loss: 4.1267 (4.1270)  time: 0.2235  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  260/89109]  eta: 5:42:48  lr: 0.000001  loss: 4.1267 (4.1269)  time: 0.2173  data: 0.0014  max mem: 11565\n",
      "Epoch: [0]  [  280/89109]  eta: 5:41:44  lr: 0.000001  loss: 4.1266 (4.1269)  time: 0.2221  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  300/89109]  eta: 5:40:47  lr: 0.000001  loss: 4.1266 (4.1269)  time: 0.2219  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  320/89109]  eta: 5:39:45  lr: 0.000001  loss: 4.1264 (4.1269)  time: 0.2200  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  340/89109]  eta: 5:38:58  lr: 0.000001  loss: 4.1265 (4.1268)  time: 0.2215  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  360/89109]  eta: 5:38:21  lr: 0.000001  loss: 4.1263 (4.1268)  time: 0.2225  data: 0.0016  max mem: 11565\n",
      "Epoch: [0]  [  380/89109]  eta: 5:37:26  lr: 0.000001  loss: 4.1263 (4.1268)  time: 0.2178  data: 0.0014  max mem: 11565\n",
      "Epoch: [0]  [  400/89109]  eta: 5:37:04  lr: 0.000001  loss: 4.1262 (4.1268)  time: 0.2243  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  420/89109]  eta: 5:36:35  lr: 0.000001  loss: 4.1258 (4.1267)  time: 0.2223  data: 0.0015  max mem: 11565\n",
      "Epoch: [0]  [  440/89109]  eta: 5:36:07  lr: 0.000001  loss: 4.1260 (4.1267)  time: 0.2218  data: 0.0015  max mem: 11565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'rasterio._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/logging/__init__.py\", line 1928, in getLogger\n",
      "    def getLogger(name=None):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-93fa285d28f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mlog_writer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/SatMAE/engine_finetune.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, criterion, data_loader, optimizer, device, epoch, loss_scaler, max_norm, mixup_fn, log_writer, args)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    print(f\"Start training for {args.epochs} epochs\")\n",
    "    start_time = time.time()\n",
    "    max_accuracy = 0.0\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "\n",
    "        if args.model_type == 'temporal':\n",
    "            train_stats = train_one_epoch_temporal(\n",
    "                model, criterion, data_loader_train,\n",
    "                optimizer, device, epoch, loss_scaler,\n",
    "                args.clip_grad, mixup_fn,\n",
    "                log_writer=log_writer,\n",
    "                args=args\n",
    "            )\n",
    "        else:\n",
    "            train_stats = train_one_epoch(\n",
    "                model, criterion, data_loader_train,\n",
    "                optimizer, device, epoch, loss_scaler,\n",
    "                args.clip_grad, mixup_fn,\n",
    "                log_writer=log_writer,\n",
    "                args=args\n",
    "            )\n",
    "\n",
    "        if args.output_dir and (epoch % args.save_every == 0 or epoch + 1 == args.epochs):\n",
    "            misc.save_model(\n",
    "                args=args, model=model, model_without_ddp=model_without_ddp, optimizer=optimizer,\n",
    "                loss_scaler=loss_scaler, epoch=epoch)\n",
    "\n",
    "        if args.model_type == 'temporal':\n",
    "            test_stats = evaluate_temporal(data_loader_val, model, device)\n",
    "        else:\n",
    "            test_stats = evaluate(data_loader_val, model, device)\n",
    "\n",
    "        print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")\n",
    "        max_accuracy = max(max_accuracy, test_stats[\"acc1\"])\n",
    "        print(f'Max accuracy: {max_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db25255-e50f-4596-8078-e6fc753b0e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eda681c8-434a-434d-ace8-6ad06c4ff9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained checkpoint from: /hdd/yuchen/satdata/weights/pretrain-vit-large-e199.pth\n"
     ]
    }
   ],
   "source": [
    "PATH = '/hdd/yuchen/satdata/weights/finetune-vit-large-e7.pth'\n",
    "checkpoint = torch.load(PATH, map_location='cpu')\n",
    "\n",
    "print(\"Load pre-trained checkpoint from: %s\" % args.finetune)\n",
    "checkpoint_model = checkpoint['model']\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "\n",
    "for k in ['pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'head.weight', 'head.bias']:\n",
    "    if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "        print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "        del checkpoint_model[k]\n",
    "\n",
    "interpolate_pos_embed(model, checkpoint_model)\n",
    "\n",
    "msg = model.load_state_dict(checkpoint_model, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443c19a-2077-434d-99dd-89a803796c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dd07e81-f6dd-40e1-909d-065f8ada4566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [    0/89110]  eta: 5 days, 2:23:19  loss: 0.1512 (0.1512)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.9444  data: 4.8474  max mem: 12255\n",
      "Test:  [   10/89110]  eta: 14:13:43  loss: 0.1512 (0.3156)  acc1: 100.0000 (93.1818)  acc5: 100.0000 (98.8636)  time: 0.5749  data: 0.4954  max mem: 12255\n",
      "Test:  [   20/89110]  eta: 10:22:06  loss: 0.1426 (0.2421)  acc1: 100.0000 (95.8333)  acc5: 100.0000 (99.4048)  time: 0.1927  data: 0.1094  max mem: 12255\n",
      "Test:  [   30/89110]  eta: 8:00:39  loss: 0.1293 (0.2097)  acc1: 100.0000 (97.1774)  acc5: 100.0000 (99.5968)  time: 0.1856  data: 0.0960  max mem: 12255\n",
      "Test:  [   40/89110]  eta: 7:35:33  loss: 0.1159 (0.1952)  acc1: 100.0000 (97.8659)  acc5: 100.0000 (99.6951)  time: 0.1892  data: 0.0924  max mem: 12255\n",
      "Test:  [   50/89110]  eta: 6:53:42  loss: 0.1150 (0.1829)  acc1: 100.0000 (98.2843)  acc5: 100.0000 (99.7549)  time: 0.2089  data: 0.1101  max mem: 12255\n",
      "Test:  [   60/89110]  eta: 6:26:26  loss: 0.1158 (0.1726)  acc1: 100.0000 (98.5656)  acc5: 100.0000 (99.7951)  time: 0.1650  data: 0.0778  max mem: 12255\n",
      "Test:  [   70/89110]  eta: 6:25:00  loss: 0.1202 (0.1675)  acc1: 100.0000 (98.7676)  acc5: 100.0000 (99.8239)  time: 0.2103  data: 0.1295  max mem: 12255\n",
      "Test:  [   80/89110]  eta: 5:57:39  loss: 0.1337 (0.1668)  acc1: 100.0000 (98.9198)  acc5: 100.0000 (99.8457)  time: 0.1820  data: 0.0885  max mem: 12255\n",
      "Test:  [   90/89110]  eta: 5:47:01  loss: 0.1501 (0.1743)  acc1: 100.0000 (98.7637)  acc5: 100.0000 (99.8626)  time: 0.1432  data: 0.0450  max mem: 12255\n",
      "Test:  [  100/89110]  eta: 5:27:07  loss: 0.1552 (0.1769)  acc1: 100.0000 (98.7624)  acc5: 100.0000 (99.8762)  time: 0.1374  data: 0.0441  max mem: 12255\n",
      "Test:  [  110/89110]  eta: 5:21:53  loss: 0.1493 (0.1744)  acc1: 100.0000 (98.8739)  acc5: 100.0000 (99.8874)  time: 0.1402  data: 0.0511  max mem: 12255\n",
      "Test:  [  120/89110]  eta: 5:18:22  loss: 0.1425 (0.1720)  acc1: 100.0000 (98.9669)  acc5: 100.0000 (99.8967)  time: 0.1851  data: 0.1052  max mem: 12255\n",
      "Test:  [  130/89110]  eta: 5:40:03  loss: 0.1265 (0.1682)  acc1: 100.0000 (99.0458)  acc5: 100.0000 (99.9046)  time: 0.2976  data: 0.2200  max mem: 12255\n",
      "Test:  [  140/89110]  eta: 5:23:11  loss: 0.1380 (0.1897)  acc1: 100.0000 (98.5816)  acc5: 100.0000 (99.5567)  time: 0.2379  data: 0.1645  max mem: 12255\n",
      "Test:  [  150/89110]  eta: 5:36:51  loss: 0.1541 (0.1857)  acc1: 100.0000 (98.6755)  acc5: 100.0000 (99.5861)  time: 0.2134  data: 0.1442  max mem: 12255\n",
      "Test:  [  160/89110]  eta: 6:07:27  loss: 0.1541 (0.1841)  acc1: 100.0000 (98.7578)  acc5: 100.0000 (99.6118)  time: 0.4587  data: 0.3850  max mem: 12255\n",
      "Test:  [  170/89110]  eta: 5:51:57  loss: 0.1363 (0.1817)  acc1: 100.0000 (98.8304)  acc5: 100.0000 (99.6345)  time: 0.3147  data: 0.2409  max mem: 12255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4f970f32947c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtest_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_temporal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtest_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m print(f\"Evaluation on {len(dataset_val)} test images- acc1: {test_stats['acc1']:.2f}%, \"\n\u001b[1;32m      6\u001b[0m             f\"acc5: {test_stats['acc5']:.2f}%\")\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/SatMAE/engine_finetune.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data_loader, model, device)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/SatMAE/util/misc.py\u001b[0m in \u001b[0;36mlog_every\u001b[0;34m(self, iterable, print_freq, header)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mlog_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mMB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'rasterio._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"/hdd/yuchen/anaconda3/envs/sat_env/lib/python3.7/logging/__init__.py\", line 1928, in getLogger\n",
      "    def getLogger(name=None):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if args.model_type == 'temporal':\n",
    "    test_stats = evaluate_temporal(data_loader_val, model, device)\n",
    "else:\n",
    "    test_stats = evaluate(data_loader_val, model, device)\n",
    "print(f\"Evaluation on {len(dataset_val)} test images- acc1: {test_stats['acc1']:.2f}%, \"\n",
    "            f\"acc5: {test_stats['acc5']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29710b24-bf8e-403d-9f69-655a2daee902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
